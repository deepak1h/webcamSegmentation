{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914bb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirments if not installed\n",
    "# !pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install opencv-python\n",
    "# !pip install pycocotools\n",
    "# !pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4efb0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import cv2\n",
    "from yolact import Yolact\n",
    "from collections import defaultdict\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils.augmentations import FastBaseTransform\n",
    "from utils import timer\n",
    "from data import cfg\n",
    "from layers.output_utils import postprocess\n",
    "from data import COLORS\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import PIL.Image, PIL.ImageTk\n",
    "from tkinter import BooleanVar, Scale\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b00eb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##SOME PARAMETERS ARGS\n",
    "global net\n",
    "global cuda_enabled\n",
    "global sc\n",
    "global top_k\n",
    "global display_text_bbx_enabled\n",
    "global img_scale\n",
    "global class_list\n",
    "\n",
    "class_list = set()\n",
    "cuda_enabled = torch.cuda.is_available()\n",
    "display_masks_enabled = cuda_enabled\n",
    "img_scale=1\n",
    "sc=0.45\n",
    "top_k =15\n",
    "color_cache = defaultdict(lambda: {})\n",
    "display_text_bbx_enabled=True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "91cd53d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model... Done.\n"
     ]
    }
   ],
   "source": [
    "print('Loading model...', end='')\n",
    "net = Yolact()\n",
    "net.load_weights(\"model/yolact_base_54_800000.pth\")\n",
    "net.eval()\n",
    "print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7c78ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF CUUDA added \n",
    "#FOR NOW IT WORKS ONLU ON CUDA MODE\n",
    "def set_default():\n",
    "    if cuda_enabled and torch.cuda.is_available():\n",
    "        cudnn.fastest = True\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    else:\n",
    "        cudnn.fastest = False\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "dcea431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING MODEL\n",
    "def load_model():\n",
    "    if cuda_enabled:\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fea1d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to prepare and display segmentation results\n",
    "\n",
    "def prep_display(dets_out, img, h, w, undo_transform=True, class_color=False, mask_alpha=0.45, fps_str=''):\n",
    "    \n",
    "    # Check if we need to undo image transformation\n",
    "    if undo_transform:\n",
    "        img_numpy = undo_image_transformation(img, w, h)  # Undo image transformation\n",
    "        if cuda_enabled:\n",
    "            img_gpu = torch.Tensor(img_numpy).cuda()  # Transfer to CPU\n",
    "        else:\n",
    "            img_gpu = torch.Tensor(img_numpy).cpu()  # Transfer to GPU\n",
    "    else:\n",
    "        img_gpu = img / 255.0  # Normalize image if not transformed\n",
    "        h, w, _ = img.shape\n",
    "    \n",
    "    # Perform post-processing on detection results\n",
    "    with timer.env('Postprocess'):\n",
    "        save = cfg.rescore_bbox\n",
    "        cfg.rescore_bbox = True\n",
    "        t = postprocess(dets_out, w, h, visualize_lincomb=False,\n",
    "                                        crop_masks=True,\n",
    "                                        score_threshold=0)\n",
    "        cfg.rescore_bbox = save\n",
    "    \n",
    "    with timer.env('Copy'):\n",
    "        idx = t[1].argsort(0, descending=True)[:top_k]  # Sort and select top detections\n",
    "        \n",
    "        if cfg.eval_mask_branch:\n",
    "            masks = t[3][idx]  # Extract masks if available\n",
    "        classes, scores, boxes = [x[idx].cpu().numpy() for x in t[:3]]  # Extract classes, scores, and boxes\n",
    "\n",
    "    # Determine the number of detections to consider\n",
    "    num_dets_to_consider = min(top_k, classes.shape[0])\n",
    "    for j in range(num_dets_to_consider):\n",
    "        if scores[j] < sc:\n",
    "            num_dets_to_consider = j\n",
    "            break\n",
    "\n",
    "    # Define a function to get color for class/category\n",
    "    def get_color(j, on_gpu=None):\n",
    "        global color_cache\n",
    "        color_idx = (classes[j] * 5 if class_color else j * 5) % len(COLORS)\n",
    "        \n",
    "        if on_gpu is not None and color_idx in color_cache[on_gpu]:\n",
    "            return color_cache[on_gpu][color_idx]\n",
    "        else:\n",
    "            color = COLORS[color_idx]\n",
    "            if not undo_transform:\n",
    "                # The image might come in as RGB or BRG, depending\n",
    "                color = (color[2], color[1], color[0])\n",
    "            if on_gpu is not None:\n",
    "                color = torch.Tensor(color).to(on_gpu).float() / 255.\n",
    "                color_cache[on_gpu][color_idx] = color\n",
    "            return color\n",
    "\n",
    "    if display_masks_enabled and cuda_enabled and cfg.eval_mask_branch and num_dets_to_consider > 0:\n",
    "        # After this, mask is of size [num_dets, h, w, 1]\n",
    "        masks = masks[:num_dets_to_consider, :, :, None]\n",
    "        colors = torch.cat([get_color(j, on_gpu=img_gpu.device.index).view(1, 1, 1, 3) for j in range(num_dets_to_consider)], dim=0)\n",
    "        masks_color = masks.repeat(1, 1, 1, 3) * colors * mask_alpha\n",
    "\n",
    "        inv_alph_masks = masks * (-mask_alpha) + 1\n",
    "\n",
    "        masks_color_summand = masks_color[0]\n",
    "        if num_dets_to_consider > 1:\n",
    "            inv_alph_cumul = inv_alph_masks[:(num_dets_to_consider-1)].cumprod(dim=0)\n",
    "            masks_color_cumul = masks_color[1:] * inv_alph_cumul\n",
    "            masks_color_summand += masks_color_cumul.sum(dim=0)\n",
    "\n",
    "        img_gpu = img_gpu * inv_alph_masks.prod(dim=0) + masks_color_summand\n",
    "\n",
    "    img_numpy = (img_gpu * 255).byte().cpu().numpy()\n",
    "\n",
    "    if num_dets_to_consider == 0:\n",
    "        return img_numpy\n",
    "\n",
    "    if display_text_bbx_enabled:\n",
    "        for j in reversed(range(num_dets_to_consider)):\n",
    "            x1, y1, x2, y2 = boxes[j, :]\n",
    "            color = get_color(j)\n",
    "            score = scores[j]\n",
    "\n",
    "            if True:\n",
    "                cv2.rectangle(img_numpy, (x1, y1), (x2, y2), color, 1)\n",
    "                \n",
    "                _class = cfg.dataset.class_names[classes[j]]\n",
    "                text_str = '%s: %.2f' % (_class, score) if True else _class\n",
    "                class_list.add(_class)\n",
    "                \n",
    "\n",
    "                font_face = cv2.FONT_HERSHEY_DUPLEX\n",
    "                font_scale = 0.6\n",
    "                font_thickness = 1\n",
    "\n",
    "                text_w, text_h = cv2.getTextSize(text_str, font_face, font_scale, font_thickness)[0]\n",
    "\n",
    "                text_pt = (x1, y1 - 3)\n",
    "                text_color = [255, 255, 255]\n",
    "\n",
    "                cv2.rectangle(img_numpy, (x1, y1), (x1 + text_w, y1 - text_h - 4), color, -1)\n",
    "                cv2.putText(img_numpy, text_str, text_pt, font_face, font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
    "    \n",
    "    return img_numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "01a63ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate an image using a segmentation model\n",
    "def evaluateimg(img):\n",
    "    \n",
    "    # Convert the image to a PyTorch tensor and transfer it to the GPU\n",
    "    if cuda_enabled:\n",
    "        frame = torch.from_numpy(img).cuda().float()\n",
    "    else:\n",
    "        frame = torch.from_numpy(img).cpu().float()\n",
    "\n",
    "    # Apply FastBaseTransform to prepare the image for model evaluation\n",
    "    batch = FastBaseTransform()(frame.unsqueeze(0))\n",
    "    \n",
    "    # Disable gradient tracking for model inference\n",
    "    with torch.no_grad():\n",
    "        preds = net(batch)  # Pass the image through the segmentation model\n",
    "\n",
    "    # Prepare the segmented image for display and return it\n",
    "    res = prep_display(preds, frame, None, None, undo_transform=False)\n",
    "    return res\n",
    "\n",
    "    # Example of how to use the 'evaluateimg' function\n",
    "    image = evaluateimg(frame)  # 'frame' is assumed to be an input image here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b76e908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting():\n",
    "    set_default()\n",
    "    load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fcc98ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nsetting()\\n# Open the default camera (camera index 0)\\ncap = cv2.VideoCapture(0)\\n# Continuously capture frames from the webcam\\nwhile True:\\n    # Read a frame from the camera\\n    ret, frame = cap.read()\\n\\n    # Check if the frame was successfully captured\\n    if not ret:\\n        # If not, break out of the loop\\n        break\\n    \\n    image = evaluateimg(frame)\\n    cv2.imshow(\"Camera Output\", image)\\n\\n    # Check if the \\'q\\' key is pressed to exit the loop\\n    if cv2.waitKey(1) & 0xFF == ord(\\'q\\'):\\n        break\\n\\n# Release the webcam (release camera resources)\\ncap.release()\\n\\n# Close all OpenCV windows\\n\\ncv2.destroyAllWindows()\\n\\nprint(\"classes we found in image\", class_list)\\n\\n'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test code\n",
    "\n",
    "'''\n",
    "\n",
    "setting()\n",
    "# Open the default camera (camera index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Continuously capture frames from the webcam\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame was successfully captured\n",
    "    if not ret:\n",
    "        # If not, break out of the loop\n",
    "        break\n",
    "    \n",
    "    image = evaluateimg(frame)\n",
    "    cv2.imshow(\"Camera Output\", image)\n",
    "\n",
    "    # Check if the 'q' key is pressed to exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam (release camera resources)\n",
    "cap.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"classes we found in image\", class_list)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a434084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_camera_feed():\n",
    "    global class_list\n",
    "    ret, frame = cap.read()  # Capture a frame from the webcam\n",
    "    \n",
    "    if ret:\n",
    "        class_list.clear()\n",
    "        # Convert the OpenCV frame to a format suitable for Tkinter\n",
    "        image = evaluateimg(frame)\n",
    "\n",
    "        #cv2.imshow('output detection', image)\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img = PIL.Image.fromarray(img)\n",
    "        w, h = img.size\n",
    "        img = img.resize((int(w*img_scale), int(h*img_scale)))\n",
    "        img = PIL.ImageTk.PhotoImage(image=img)\n",
    "\n",
    "        # Update the label with the new frame\n",
    "        label.config(image=img)\n",
    "        label.image = img\n",
    "        \n",
    "\n",
    "    # Schedule the next update\n",
    "    root.after(10, update_camera_feed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1764d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_cuda():\n",
    "    global cuda_enabled\n",
    "    cuda_enabled = cuda_var.get()\n",
    "    if cuda_enabled:\n",
    "        display_masks_checkbox.config(state=\"normal\")  # Enable the checkbox\n",
    "    else:\n",
    "        display_masks_checkbox.config(state=\"disabled\")  # Disable the checkbox\n",
    "    setting()\n",
    "\n",
    "def update_sc(value):\n",
    "    global sc\n",
    "    sc = float(value)\n",
    "    \n",
    "def update_img_scale(value):\n",
    "    global img_scale\n",
    "    img_scale = float(value)\n",
    "\n",
    "def update_top_k(value):\n",
    "    global top_k\n",
    "    top_k = int(value)\n",
    "\n",
    "def toggle_display_masks():\n",
    "    global display_masks_enabled\n",
    "    display_masks_enabled = display_masks_var.get()\n",
    "\n",
    "def toggle_display_text_bbx():\n",
    "    global display_text_bbx_enabled\n",
    "    display_text_bbx_enabled = display_text_bbx_var.get()\n",
    "    setting()\n",
    "    \n",
    "def update_set_label():\n",
    "    current_contents = '\\n'.join(class_list)  \n",
    "    set_label.config(text=current_contents)\n",
    "    root.after(1000, update_set_label)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f11af102",
   "metadata": {},
   "outputs": [],
   "source": [
    "setting()\n",
    "class_list=set()\n",
    "root = tk.Tk()\n",
    "root.title(\"Camera Feed\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "label = ttk.Label(root)\n",
    "label.pack(side=\"right\")\n",
    "\n",
    "#variables\n",
    "cuda_var = BooleanVar()\n",
    "display_masks_var = BooleanVar()\n",
    "display_text_bbx_var = BooleanVar()\n",
    "\n",
    "cuda_var.set(cuda_enabled)\n",
    "display_masks_var.set(display_masks_enabled)\n",
    "display_text_bbx_var.set(display_text_bbx_enabled)\n",
    "\n",
    "# Checkboxes\n",
    "\n",
    "cuda_checkbox = ttk.Checkbutton(root, text=\"CUDA Enable\", variable=cuda_var, command=toggle_cuda)\n",
    "cuda_checkbox.pack()\n",
    "\n",
    "display_masks_checkbox = ttk.Checkbutton(root, text=\"Display Masks\", variable=display_masks_var, command=toggle_display_masks)\n",
    "display_masks_checkbox.pack()\n",
    "\n",
    "display_text_bbx_checkbox = ttk.Checkbutton(root, text=\"Display Text/BBX\", variable=display_text_bbx_var, command=toggle_display_text_bbx)\n",
    "display_text_bbx_checkbox.pack()\n",
    "\n",
    "# Sliders\n",
    "sc_label = ttk.Label(root, text=\"Select Criteria\")\n",
    "sc_label.pack()\n",
    "sc_scale = Scale(root, from_=0, to=1, resolution=0.01, orient=\"horizontal\", command=update_sc)\n",
    "sc_scale.set(sc)\n",
    "sc_scale.pack()\n",
    "\n",
    "img_scale_label = ttk.Label(root, text=\"Image Scale\")\n",
    "img_scale_label.pack()\n",
    "img_scale_label = Scale(root, from_=0.5, to=2, resolution=0.01, orient=\"horizontal\", command=update_img_scale)\n",
    "img_scale_label.set(img_scale)\n",
    "img_scale_label.pack()\n",
    "\n",
    "top_k_label = ttk.Label(root, text=\"Top K Boxes\")\n",
    "top_k_label.pack()\n",
    "top_k_scale = Scale(root, from_=1, to=100, orient=\"horizontal\", command=update_top_k)\n",
    "top_k_scale.set(top_k)\n",
    "top_k_scale.pack()\n",
    "\n",
    "# Create a label for displaying dynamic strings\n",
    "set_label = ttk.Label(root, text=\"\")\n",
    "set_label.pack()\n",
    "\n",
    "update_camera_feed()\n",
    "update_set_label()\n",
    "\n",
    "root.mainloop()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5f0733e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if shows pyimageXX error run this and cut all windows and re run\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7b4729ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person'}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e3958c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
